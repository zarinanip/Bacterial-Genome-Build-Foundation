{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Zarina\n",
    "\n",
    "## Choosing the models\n",
    "I wanted to focus on kmer data. Both of the models I chose are trained on kmers instead of presence/absence. I was originally interested in the gradient boosting model, and due to the processing power availability to me, chose to use basic decision trees as my base estimator. I did not want to use the linear models as I felt like I could not guarantee that the kmers would fit the linear regression assumptions. For curiosities sake, I also chose to do a random forest model to see how it compares to the gradient boosting model with the same base estimator.\n",
    "\n",
    "I am using KNN (K Nearest Neighbour) as a baseline model. In week 4, we found that it has a peak accuracy of 84%, therefore, I am hoping to generate a model with an accuracy greater than 84%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import bayes_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 130\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    # Load Kmer data\n",
    "    train_kmers = np.load('../data/train_test_data/train_kmers.npy', allow_pickle=True)\n",
    "    test_kmers = np.load('../data/train_test_data/test_kmers.npy', allow_pickle=True)\n",
    "\n",
    "    # Load target data & IDs\n",
    "    y_train = np.load('../data/train_test_data/y_train.npy', allow_pickle=True)\n",
    "    y_train_ids = np.load('../data/train_test_data/train_ids.npy', allow_pickle=True).astype(str)\n",
    "    y_test_ids = np.load('../data/train_test_data/test_ids.npy', allow_pickle=True).astype(str)\n",
    "    \n",
    "    return train_kmers, test_kmers, y_train, y_train_ids, y_test_ids\n",
    "\n",
    "X_train_kmers, X_test_kmers, y_train, y_train_ids, y_test_ids = load_data()\n",
    "y_train = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold CV\n",
    "Below is a stratified K-Fold Cross-Validation. I chose to stratify the distribution to get the best mix possible for my training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "kfold = sklearn.model_selection.StratifiedKFold(\n",
    "    n_splits = K,\n",
    "    shuffle = True, # Want to shuffle as seen in slides\n",
    "    random_state = seed, # To ensure reproducible results\n",
    ")\n",
    "\n",
    "kfold_dfs = {}\n",
    "val_idx = {}\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(X_train_kmers, y_train)):\n",
    "    \n",
    "    val_idx[i] = val_index\n",
    "\n",
    "    kfold_dfs[i] = (X_train_kmers[train_index], X_train_kmers[val_index], y_train[train_index], y_train[val_index])\n",
    "\n",
    "# Specify fold 0\n",
    "X_train_fold_0 = kfold_dfs[0][0]\n",
    "X_val_fold_0 = kfold_dfs[0][1]\n",
    "y_train_fold_0 = kfold_dfs[0][2]\n",
    "y_val_fold_0 = kfold_dfs[0][3]\n",
    "\n",
    "# Specify fold 1\n",
    "X_train_fold_1 = kfold_dfs[1][0]\n",
    "X_val_fold_1 = kfold_dfs[1][1]\n",
    "y_train_fold_1 = kfold_dfs[1][2]\n",
    "y_val_fold_1 = kfold_dfs[1][3]\n",
    "\n",
    "# Specify fold 2\n",
    "X_train_fold_2 = kfold_dfs[2][0]\n",
    "X_val_fold_2 = kfold_dfs[2][1]\n",
    "y_train_fold_2 = kfold_dfs[2][2]\n",
    "y_val_fold_2 = kfold_dfs[2][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest Model\n",
    "A random forest is more robust than a simple decision tree. The hyperparameters of interest are the number of trees in the forest (n_estimators) and the tree depth (max_depth) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model_fit_0(numberTrees, sizeTrees):\n",
    "     # Create model\n",
    "    randomForestModel = ensemble.RandomForestClassifier(n_estimators=int(numberTrees), max_depth=int(sizeTrees), random_state = seed)\n",
    "    \n",
    "    # Fit model\n",
    "    randomForestModel.fit(X_train_fold_0, y_train_fold_0)\n",
    "\n",
    "    # Evaluate the model and return the evaluation score\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_0, randomForestModel.predict(X_val_fold_0))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "I went with a Bayesian optimizer to find the hyperparameters for my random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | number... | sizeTrees |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8125   \u001b[0m | \u001b[0m7.94     \u001b[0m | \u001b[0m8.477    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.8325   \u001b[0m | \u001b[95m28.18    \u001b[0m | \u001b[95m4.019    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8325   \u001b[0m | \u001b[0m25.2     \u001b[0m | \u001b[0m23.11    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.8425   \u001b[0m | \u001b[95m19.61    \u001b[0m | \u001b[95m4.035    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.835    \u001b[0m | \u001b[0m49.94    \u001b[0m | \u001b[0m19.5     \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m36.78    \u001b[0m | \u001b[0m1.759    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m40.71    \u001b[0m | \u001b[0m2.236    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.855    \u001b[0m | \u001b[95m28.99    \u001b[0m | \u001b[95m9.147    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.815    \u001b[0m | \u001b[0m11.67    \u001b[0m | \u001b[0m19.34    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8375   \u001b[0m | \u001b[0m47.44    \u001b[0m | \u001b[0m17.95    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.815    \u001b[0m | \u001b[0m25.69    \u001b[0m | \u001b[0m12.11    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m29.31    \u001b[0m | \u001b[0m8.021    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m29.0     \u001b[0m | \u001b[0m9.161    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m28.08    \u001b[0m | \u001b[0m9.161    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m28.19    \u001b[0m | \u001b[0m9.92     \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.825    \u001b[0m | \u001b[0m29.33    \u001b[0m | \u001b[0m10.86    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m27.1     \u001b[0m | \u001b[0m9.762    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.815    \u001b[0m | \u001b[0m26.64    \u001b[0m | \u001b[0m8.746    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.825    \u001b[0m | \u001b[0m27.4     \u001b[0m | \u001b[0m10.4     \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m28.52    \u001b[0m | \u001b[0m9.212    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m27.7     \u001b[0m | \u001b[0m9.388    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.81     \u001b[0m | \u001b[0m20.21    \u001b[0m | \u001b[0m2.981    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8225   \u001b[0m | \u001b[0m19.18    \u001b[0m | \u001b[0m5.021    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.8425   \u001b[0m | \u001b[0m29.91    \u001b[0m | \u001b[0m9.733    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m28.83    \u001b[0m | \u001b[0m9.968    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8375   \u001b[0m | \u001b[0m26.21    \u001b[0m | \u001b[0m10.02    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.8425   \u001b[0m | \u001b[0m31.32    \u001b[0m | \u001b[0m9.312    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.825    \u001b[0m | \u001b[0m32.19    \u001b[0m | \u001b[0m10.14    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m31.66    \u001b[0m | \u001b[0m8.189    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.84     \u001b[0m | \u001b[0m47.73    \u001b[0m | \u001b[0m19.41    \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# Bounded region of parameter space\n",
    "parameter_limits = {'numberTrees': (1, 50), 'sizeTrees': (1, 25)}\n",
    "\n",
    "optimizer0 = bayes_opt.BayesianOptimization(\n",
    "    f = random_forest_model_fit_0,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Fit the model using our custom optimizer\n",
    "optimizer0.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Random Forest Model for Fold 0\n",
    "Based on the above, the best model on fold 0 has a forest with a size of 28, and a tree depth of 9, resulting in an accuracy of 0.855. \n",
    "\n",
    "I ran the model on the full set to submit to Kaggle, with a private/public score of 0.95625/0.91875."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      R\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestFold0 = ensemble.RandomForestClassifier(n_estimators=28, max_depth=9, random_state = seed)\n",
    "randomForestFold0.fit(X_train_kmers, y_train)\n",
    "\n",
    "# Make test predictions and save out as a dataframe\n",
    "test_preds = randomForestFold0.predict(X_test_kmers)\n",
    "\n",
    "# Save\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"randomForestFold0.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the Random Forest Model on Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | number... | sizeTrees |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8473   \u001b[0m | \u001b[0m7.94     \u001b[0m | \u001b[0m8.477    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.8797   \u001b[0m | \u001b[95m28.18    \u001b[0m | \u001b[95m4.019    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8498   \u001b[0m | \u001b[0m25.2     \u001b[0m | \u001b[0m23.11    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.8497   \u001b[0m | \u001b[0m19.61    \u001b[0m | \u001b[0m4.035    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8723   \u001b[0m | \u001b[0m49.94    \u001b[0m | \u001b[0m19.5     \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8473   \u001b[0m | \u001b[0m36.78    \u001b[0m | \u001b[0m1.759    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8273   \u001b[0m | \u001b[0m40.71    \u001b[0m | \u001b[0m2.236    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8648   \u001b[0m | \u001b[0m28.99    \u001b[0m | \u001b[0m9.147    \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.8948   \u001b[0m | \u001b[95m11.67    \u001b[0m | \u001b[95m19.34    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8623   \u001b[0m | \u001b[0m47.44    \u001b[0m | \u001b[0m17.95    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8897   \u001b[0m | \u001b[0m10.22    \u001b[0m | \u001b[0m22.55    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8823   \u001b[0m | \u001b[0m6.415    \u001b[0m | \u001b[0m18.96    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8748   \u001b[0m | \u001b[0m15.56    \u001b[0m | \u001b[0m22.17    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8049   \u001b[0m | \u001b[0m1.188    \u001b[0m | \u001b[0m24.89    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8773   \u001b[0m | \u001b[0m15.44    \u001b[0m | \u001b[0m14.95    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8798   \u001b[0m | \u001b[0m40.44    \u001b[0m | \u001b[0m24.95    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8623   \u001b[0m | \u001b[0m47.79    \u001b[0m | \u001b[0m24.85    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8798   \u001b[0m | \u001b[0m36.14    \u001b[0m | \u001b[0m19.88    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8723   \u001b[0m | \u001b[0m33.9     \u001b[0m | \u001b[0m24.69    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8848   \u001b[0m | \u001b[0m9.658    \u001b[0m | \u001b[0m15.92    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.8473   \u001b[0m | \u001b[0m1.092    \u001b[0m | \u001b[0m1.034    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8798   \u001b[0m | \u001b[0m37.23    \u001b[0m | \u001b[0m13.67    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8548   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m9.643    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.8698   \u001b[0m | \u001b[0m32.11    \u001b[0m | \u001b[0m16.1     \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8823   \u001b[0m | \u001b[0m9.624    \u001b[0m | \u001b[0m19.51    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8273   \u001b[0m | \u001b[0m3.327    \u001b[0m | \u001b[0m14.99    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.8798   \u001b[0m | \u001b[0m40.43    \u001b[0m | \u001b[0m18.29    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8948   \u001b[0m | \u001b[0m12.0     \u001b[0m | \u001b[0m24.97    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8648   \u001b[0m | \u001b[0m22.22    \u001b[0m | \u001b[0m13.86    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8573   \u001b[0m | \u001b[0m13.88    \u001b[0m | \u001b[0m18.01    \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "def random_forest_model_fit_1(numberTrees, sizeTrees):\n",
    "    \n",
    "    randomForestModel = ensemble.RandomForestClassifier(n_estimators=int(numberTrees), max_depth=int(sizeTrees), random_state = seed)\n",
    "    randomForestModel.fit(X_train_fold_1, y_train_fold_1)\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_1, randomForestModel.predict(X_val_fold_1))\n",
    "\n",
    "    return score\n",
    "\n",
    "# We do not need to restate the parameter limits as they are the same\n",
    "\n",
    "optimizer1 = bayes_opt.BayesianOptimization(\n",
    "    f = random_forest_model_fit_1,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "optimizer1.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Random Forest Model for Fold 1\n",
    "This suggests that the best model for fold 1 would be a forest with a size of 11, and a tree depth of 19, resulting in an accuracy of 0.8948\n",
    "\n",
    "Again I saved the results here to submit to Kaggle, which predicted a score of 0.95000/0.90000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      R\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestFold1 = ensemble.RandomForestClassifier(n_estimators=11, max_depth=19, random_state = seed)\n",
    "randomForestFold1.fit(X_train_kmers, y_train)\n",
    "\n",
    "test_preds = randomForestFold1.predict(X_test_kmers)\n",
    "\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"randomForestFold1.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the Random Forest Model on Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | number... | sizeTrees |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7699   \u001b[0m | \u001b[0m7.94     \u001b[0m | \u001b[0m8.477    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.7899   \u001b[0m | \u001b[95m28.18    \u001b[0m | \u001b[95m4.019    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.7524   \u001b[0m | \u001b[0m25.2     \u001b[0m | \u001b[0m23.11    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.7799   \u001b[0m | \u001b[0m19.61    \u001b[0m | \u001b[0m4.035    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.7649   \u001b[0m | \u001b[0m49.94    \u001b[0m | \u001b[0m19.5     \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.7773   \u001b[0m | \u001b[0m36.78    \u001b[0m | \u001b[0m1.759    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m40.71    \u001b[0m | \u001b[0m2.236    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.7849   \u001b[0m | \u001b[0m28.99    \u001b[0m | \u001b[0m9.147    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7524   \u001b[0m | \u001b[0m11.67    \u001b[0m | \u001b[0m19.34    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.7649   \u001b[0m | \u001b[0m47.44    \u001b[0m | \u001b[0m17.95    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6698   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.7974   \u001b[0m | \u001b[95m49.98    \u001b[0m | \u001b[95m5.215    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.7298   \u001b[0m | \u001b[0m1.068    \u001b[0m | \u001b[0m24.92    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.7773   \u001b[0m | \u001b[0m49.87    \u001b[0m | \u001b[0m1.143    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m38.73    \u001b[0m | \u001b[0m10.92    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m10.65    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.7649   \u001b[0m | \u001b[0m38.8     \u001b[0m | \u001b[0m25.0     \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.7624   \u001b[0m | \u001b[0m18.55    \u001b[0m | \u001b[0m11.59    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.7824   \u001b[0m | \u001b[0m45.77    \u001b[0m | \u001b[0m6.6      \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.7773   \u001b[0m | \u001b[0m24.36    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.7649   \u001b[0m | \u001b[0m33.39    \u001b[0m | \u001b[0m16.76    \u001b[0m |\n",
      "| \u001b[95m22       \u001b[0m | \u001b[95m0.8049   \u001b[0m | \u001b[95m33.22    \u001b[0m | \u001b[95m6.531    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.7773   \u001b[0m | \u001b[0m14.44    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.7899   \u001b[0m | \u001b[0m32.07    \u001b[0m | \u001b[0m4.128    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m33.62    \u001b[0m | \u001b[0m9.448    \u001b[0m |\n",
      "| \u001b[95m26       \u001b[0m | \u001b[95m0.8149   \u001b[0m | \u001b[95m36.67    \u001b[0m | \u001b[95m6.075    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.7949   \u001b[0m | \u001b[0m39.44    \u001b[0m | \u001b[0m6.548    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8099   \u001b[0m | \u001b[0m24.37    \u001b[0m | \u001b[0m7.377    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.7499   \u001b[0m | \u001b[0m24.52    \u001b[0m | \u001b[0m11.29    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8074   \u001b[0m | \u001b[0m24.22    \u001b[0m | \u001b[0m5.202    \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "def random_forest_model_fit_2(numberTrees, sizeTrees):\n",
    "    randomForestModel = ensemble.RandomForestClassifier(n_estimators=int(numberTrees), max_depth=int(sizeTrees), random_state = seed)\n",
    "    randomForestModel.fit(X_train_fold_2, y_train_fold_2)\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_2, randomForestModel.predict(X_val_fold_2))\n",
    "\n",
    "    return score\n",
    "\n",
    "optimizer2 = bayes_opt.BayesianOptimization(\n",
    "    f = random_forest_model_fit_2,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "optimizer2.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Random Forest Model for Fold 2\n",
    "This suggests that the best model for fold 2 would be a forest with a size of 36, and a tree depth of 6, resulting in an accuracy of 0.8149\n",
    "\n",
    "Kaggle had a score of 0.91875/0.87500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      R\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForestFold2 = ensemble.RandomForestClassifier(n_estimators=36, max_depth=6, random_state = seed)\n",
    "randomForestFold2.fit(X_train_kmers, y_train)\n",
    "\n",
    "test_preds = randomForestFold2.predict(X_test_kmers)\n",
    "\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"randomForestFold2.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Random Forest Model\n",
    "Based on the results of the three optimized models above, the best model would be the one trained on fold 1. (Forest size of 11, and a tree depth of 19) as it had the highest accuracy of 0.8948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Gradient Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boost_model_fit_0(numberTrees, sizeTrees, learnRate):\n",
    "    # Create model\n",
    "    gradientBoostModel = sklearn.ensemble.AdaBoostClassifier(\n",
    "        estimator = tree.DecisionTreeClassifier(max_depth=int(sizeTrees)), # Can choose any simple base estimator\n",
    "        n_estimators = int(numberTrees),\n",
    "        learning_rate = float(learnRate), # Another parameter to tune\n",
    "        algorithm=\"SAMME\",\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    gradientBoostModel.fit(X_train_fold_0, y_train_fold_0)\n",
    "\n",
    "    # Evaluate the model and return the evaluation score\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_0, gradientBoostModel.predict(X_val_fold_0))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Model Optimization\n",
    "Through trial and error, I found a rough upper bound of the learning rate of approximately 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learnRate | number... | sizeTrees |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7875   \u001b[0m | \u001b[0m4.399    \u001b[0m | \u001b[0m16.27    \u001b[0m | \u001b[0m14.32    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.7925   \u001b[0m | \u001b[95m4.019    \u001b[0m | \u001b[95m25.2     \u001b[0m | \u001b[95m23.11    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.795    \u001b[0m | \u001b[95m10.12    \u001b[0m | \u001b[95m7.196    \u001b[0m | \u001b[95m24.97    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.82     \u001b[0m | \u001b[95m19.5     \u001b[0m | \u001b[95m36.78    \u001b[0m | \u001b[95m1.759    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.795    \u001b[0m | \u001b[0m20.45    \u001b[0m | \u001b[0m3.523    \u001b[0m | \u001b[0m14.71    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.785    \u001b[0m | \u001b[0m9.147    \u001b[0m | \u001b[0m11.67    \u001b[0m | \u001b[0m19.34    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8175   \u001b[0m | \u001b[0m23.75    \u001b[0m | \u001b[0m35.6     \u001b[0m | \u001b[0m23.36    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.78     \u001b[0m | \u001b[0m11.53    \u001b[0m | \u001b[0m31.72    \u001b[0m | \u001b[0m17.02    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7925   \u001b[0m | \u001b[0m2.883    \u001b[0m | \u001b[0m4.284    \u001b[0m | \u001b[0m12.6     \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.795    \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m40.26    \u001b[0m | \u001b[0m18.79    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m21.83    \u001b[0m | \u001b[0m38.81    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:695: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/base.py:1474: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.255    \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m32.69    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6875   \u001b[0m | \u001b[0m19.77    \u001b[0m | \u001b[0m40.5     \u001b[0m | \u001b[0m3.821    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8075   \u001b[0m | \u001b[0m22.83    \u001b[0m | \u001b[0m35.79    \u001b[0m | \u001b[0m20.38    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.795    \u001b[0m | \u001b[0m20.24    \u001b[0m | \u001b[0m38.59    \u001b[0m | \u001b[0m23.43    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.77     \u001b[0m | \u001b[0m19.05    \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m22.96    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.785    \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m40.54    \u001b[0m | \u001b[0m23.52    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m14.17    \u001b[0m | \u001b[0m36.1     \u001b[0m | \u001b[0m1.703    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.7025   \u001b[0m | \u001b[0m12.86    \u001b[0m | \u001b[0m32.6     \u001b[0m | \u001b[0m5.656    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m11.64    \u001b[0m | \u001b[0m40.29    \u001b[0m | \u001b[0m1.045    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m6.95     \u001b[0m | \u001b[0m37.9     \u001b[0m | \u001b[0m1.861    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.82     \u001b[0m | \u001b[0m6.795    \u001b[0m | \u001b[0m43.18    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8025   \u001b[0m | \u001b[0m8.417    \u001b[0m | \u001b[0m41.5     \u001b[0m | \u001b[0m5.937    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.695    \u001b[0m | \u001b[0m2.074    \u001b[0m | \u001b[0m40.86    \u001b[0m | \u001b[0m3.639    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.7125   \u001b[0m | \u001b[0m10.44    \u001b[0m | \u001b[0m46.75    \u001b[0m | \u001b[0m2.107    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8075   \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m30.73    \u001b[0m | \u001b[0m21.64    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.7875   \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m32.09    \u001b[0m | \u001b[0m16.18    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.7875   \u001b[0m | \u001b[0m6.633    \u001b[0m | \u001b[0m5.102    \u001b[0m | \u001b[0m18.68    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.795    \u001b[0m | \u001b[0m3.372    \u001b[0m | \u001b[0m9.881    \u001b[0m | \u001b[0m15.56    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.795    \u001b[0m | \u001b[0m8.009    \u001b[0m | \u001b[0m8.272    \u001b[0m | \u001b[0m13.05    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Bounded region of parameter space\n",
    "parameter_limits = {'numberTrees': (1, 50), 'sizeTrees': (1, 25), 'learnRate': (1.0, 25.0)}\n",
    "\n",
    "optimizer0 = bayes_opt.BayesianOptimization(\n",
    "    f = gradient_boost_model_fit_0,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Fit the model using our custom optimizer\n",
    "optimizer0.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Gradient Boost Model for Fold 0\n",
    "Based on the above, the best model on fold 0 has a forest with a size of 36, a tree depth of 1, and a learning rate of 19.5 resulting in an accuracy of 0.82\n",
    "\n",
    "Kaggle score: 0.85625/0.83125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      S\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientBoostFold0 = sklearn.ensemble.AdaBoostClassifier(estimator = tree.DecisionTreeClassifier(max_depth=1), n_estimators = 36, learning_rate = 19.5, algorithm=\"SAMME\")\n",
    "\n",
    "gradientBoostFold0.fit(X_train_kmers, y_train)\n",
    "\n",
    "# Make test predictions and save out as a dataframe\n",
    "test_preds = gradientBoostFold0.predict(X_test_kmers)\n",
    "\n",
    "# Save\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"gradientBoostFold0.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same steps for the other two folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learnRate | number... | sizeTrees |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8022   \u001b[0m | \u001b[0m4.399    \u001b[0m | \u001b[0m16.27    \u001b[0m | \u001b[0m14.32    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.8247   \u001b[0m | \u001b[95m4.019    \u001b[0m | \u001b[95m25.2     \u001b[0m | \u001b[95m23.11    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8047   \u001b[0m | \u001b[0m10.12    \u001b[0m | \u001b[0m7.196    \u001b[0m | \u001b[0m24.97    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.8423   \u001b[0m | \u001b[95m19.5     \u001b[0m | \u001b[95m36.78    \u001b[0m | \u001b[95m1.759    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.7997   \u001b[0m | \u001b[0m20.45    \u001b[0m | \u001b[0m3.523    \u001b[0m | \u001b[0m14.71    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8372   \u001b[0m | \u001b[0m9.147    \u001b[0m | \u001b[0m11.67    \u001b[0m | \u001b[0m19.34    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m23.75    \u001b[0m | \u001b[0m35.6     \u001b[0m | \u001b[0m23.36    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8147   \u001b[0m | \u001b[0m11.53    \u001b[0m | \u001b[0m31.72    \u001b[0m | \u001b[0m17.02    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7847   \u001b[0m | \u001b[0m2.883    \u001b[0m | \u001b[0m4.284    \u001b[0m | \u001b[0m12.6     \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8272   \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m40.26    \u001b[0m | \u001b[0m18.79    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6865   \u001b[0m | \u001b[0m18.85    \u001b[0m | \u001b[0m36.03    \u001b[0m | \u001b[0m2.146    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8172   \u001b[0m | \u001b[0m20.04    \u001b[0m | \u001b[0m24.73    \u001b[0m | \u001b[0m18.9     \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.581    \u001b[0m | \u001b[0m18.7     \u001b[0m | \u001b[0m11.51    \u001b[0m | \u001b[0m2.163    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6865   \u001b[0m | \u001b[0m14.73    \u001b[0m | \u001b[0m46.53    \u001b[0m | \u001b[0m2.709    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8047   \u001b[0m | \u001b[0m20.4     \u001b[0m | \u001b[0m3.49     \u001b[0m | \u001b[0m14.97    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m19.97    \u001b[0m | \u001b[0m37.17    \u001b[0m | \u001b[0m1.378    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8172   \u001b[0m | \u001b[0m20.04    \u001b[0m | \u001b[0m37.87    \u001b[0m | \u001b[0m2.762    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8047   \u001b[0m | \u001b[0m8.105    \u001b[0m | \u001b[0m11.04    \u001b[0m | \u001b[0m19.77    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m19.14    \u001b[0m | \u001b[0m37.51    \u001b[0m | \u001b[0m1.182    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8297   \u001b[0m | \u001b[0m8.885    \u001b[0m | \u001b[0m13.14    \u001b[0m | \u001b[0m19.15    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.8047   \u001b[0m | \u001b[0m10.09    \u001b[0m | \u001b[0m11.61    \u001b[0m | \u001b[0m18.01    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8247   \u001b[0m | \u001b[0m10.04    \u001b[0m | \u001b[0m12.26    \u001b[0m | \u001b[0m20.08    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.7947   \u001b[0m | \u001b[0m7.618    \u001b[0m | \u001b[0m12.57    \u001b[0m | \u001b[0m18.39    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m18.8     \u001b[0m | \u001b[0m38.76    \u001b[0m | \u001b[0m1.974    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m17.45    \u001b[0m | \u001b[0m38.91    \u001b[0m | \u001b[0m1.144    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m18.59    \u001b[0m | \u001b[0m40.02    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.6865   \u001b[0m | \u001b[0m17.8     \u001b[0m | \u001b[0m40.49    \u001b[0m | \u001b[0m2.728    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m20.26    \u001b[0m | \u001b[0m38.62    \u001b[0m | \u001b[0m1.027    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m20.14    \u001b[0m | \u001b[0m40.48    \u001b[0m | \u001b[0m1.07     \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8423   \u001b[0m | \u001b[0m21.88    \u001b[0m | \u001b[0m41.46    \u001b[0m | \u001b[0m1.094    \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "def gradient_boost_model_fit_1(numberTrees, sizeTrees, learnRate):\n",
    "\n",
    "    gradientBoostModel = sklearn.ensemble.AdaBoostClassifier(\n",
    "        estimator = tree.DecisionTreeClassifier(max_depth=int(sizeTrees)), # Can choose any simple base estimator\n",
    "        n_estimators = int(numberTrees),\n",
    "        learning_rate = float(learnRate), # Another parameter to tune\n",
    "        algorithm=\"SAMME\",\n",
    "    )\n",
    "    \n",
    "    gradientBoostModel.fit(X_train_fold_1, y_train_fold_1)\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_1, gradientBoostModel.predict(X_val_fold_1))\n",
    "    \n",
    "    return score\n",
    "\n",
    "optimizer1 = bayes_opt.BayesianOptimization(\n",
    "    f = gradient_boost_model_fit_1,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "optimizer1.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Gradient Boost Model for Fold 1\n",
    "Based on the above, the best model on fold 1 has a forest with a size of 25, a tree depth of 23, and a learning rate of 4.019 resulting in an accuracy of 0.8523\n",
    "\n",
    "Kaggle score: 0.86250/0.86250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      S\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientBoostFold1 = sklearn.ensemble.AdaBoostClassifier(estimator = tree.DecisionTreeClassifier(max_depth=23), n_estimators = 25, learning_rate = 4.019, algorithm=\"SAMME\")\n",
    "\n",
    "gradientBoostFold1.fit(X_train_kmers, y_train)\n",
    "\n",
    "test_preds = gradientBoostFold1.predict(X_test_kmers)\n",
    "\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"gradientBoostFold1.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learnRate | number... | sizeTrees |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m4.399    \u001b[0m | \u001b[0m16.27    \u001b[0m | \u001b[0m14.32    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.7124   \u001b[0m | \u001b[0m4.019    \u001b[0m | \u001b[0m25.2     \u001b[0m | \u001b[0m23.11    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.7249   \u001b[0m | \u001b[0m10.12    \u001b[0m | \u001b[0m7.196    \u001b[0m | \u001b[0m24.97    \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.7873   \u001b[0m | \u001b[95m19.5     \u001b[0m | \u001b[95m36.78    \u001b[0m | \u001b[95m1.759    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.7149   \u001b[0m | \u001b[0m20.45    \u001b[0m | \u001b[0m3.523    \u001b[0m | \u001b[0m14.71    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.7624   \u001b[0m | \u001b[0m9.147    \u001b[0m | \u001b[0m11.67    \u001b[0m | \u001b[0m19.34    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.7224   \u001b[0m | \u001b[0m23.75    \u001b[0m | \u001b[0m35.6     \u001b[0m | \u001b[0m23.36    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.7174   \u001b[0m | \u001b[0m11.53    \u001b[0m | \u001b[0m31.72    \u001b[0m | \u001b[0m17.02    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.7249   \u001b[0m | \u001b[0m2.883    \u001b[0m | \u001b[0m4.284    \u001b[0m | \u001b[0m12.6     \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.7349   \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m40.26    \u001b[0m | \u001b[0m18.79    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m6.716    \u001b[0m | \u001b[0m23.38    \u001b[0m | \u001b[0m23.29    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m20.95    \u001b[0m | \u001b[0m38.21    \u001b[0m | \u001b[0m1.69     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:695: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/base.py:1474: UserWarning: Sample weights have reached infinite values, at iteration 2, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m24.32    \u001b[0m | \u001b[0m33.35    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m20.18    \u001b[0m | \u001b[0m25.23    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m15.56    \u001b[0m | \u001b[0m49.8     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:695: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "/home/zarina/miniconda3/envs/etbg-env/lib/python3.10/site-packages/sklearn/base.py:1474: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.2203   \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m8.898    \u001b[0m | \u001b[0m47.68    \u001b[0m | \u001b[0m1.139    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.7149   \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m8.698    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.7298   \u001b[0m | \u001b[0m22.45    \u001b[0m | \u001b[0m29.88    \u001b[0m | \u001b[0m9.005    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m12.78    \u001b[0m | \u001b[0m41.55    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m10.61    \u001b[0m | \u001b[0m28.2     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.2203   \u001b[0m | \u001b[0m12.74    \u001b[0m | \u001b[0m18.54    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.7873   \u001b[0m | \u001b[0m6.695    \u001b[0m | \u001b[0m34.76    \u001b[0m | \u001b[0m1.629    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.7674   \u001b[0m | \u001b[0m12.46    \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m6.739    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.7349   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m30.76    \u001b[0m | \u001b[0m8.185    \u001b[0m |\n",
      "| \u001b[95m26       \u001b[0m | \u001b[95m0.7924   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m42.39    \u001b[0m | \u001b[95m5.712    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.7249   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m41.9     \u001b[0m | \u001b[0m15.26    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.7449   \u001b[0m | \u001b[0m18.48    \u001b[0m | \u001b[0m17.15    \u001b[0m | \u001b[0m24.32    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m1.031    \u001b[0m | \u001b[0m13.35    \u001b[0m | \u001b[0m23.81    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.7274   \u001b[0m | \u001b[0m8.279    \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m8.36     \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "def gradient_boost_model_fit_2(numberTrees, sizeTrees, learnRate):\n",
    "\n",
    "    gradientBoostModel = sklearn.ensemble.AdaBoostClassifier(\n",
    "        estimator = tree.DecisionTreeClassifier(max_depth=int(sizeTrees)), # Can choose any simple base estimator\n",
    "        n_estimators = int(numberTrees),\n",
    "        learning_rate = float(learnRate), # Another parameter to tune\n",
    "        algorithm=\"SAMME\",\n",
    "    )\n",
    "    \n",
    "    gradientBoostModel.fit(X_train_fold_2, y_train_fold_2)\n",
    "    score = sklearn.metrics.balanced_accuracy_score(y_val_fold_2, gradientBoostModel.predict(X_val_fold_2))\n",
    "    \n",
    "    return score\n",
    "\n",
    "optimizer2 = bayes_opt.BayesianOptimization(\n",
    "    f = gradient_boost_model_fit_2,\n",
    "    pbounds = parameter_limits,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "optimizer2.maximize(\n",
    "    init_points=10, # Arbitrary larger number to increase spread\n",
    "    n_iter=20, # Arbitrary large-ish number to optimize search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Gradient Boost Model for Fold 2\n",
    "Based on the above, the best model on fold 2 has a forest with a size of 36, a tree depth of 1, and a learning rate of 19.5 resulting in an accuracy of 0.7873\n",
    "These are the same parameters as fold 0!\n",
    "\n",
    "Kaggle score: 0.85625/0.83125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562.42833</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562.42739</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562.22823</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562.45646</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.22547</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genome_id y_pred\n",
       "0  562.42833      S\n",
       "1  562.42739      R\n",
       "2  562.22823      S\n",
       "3  562.45646      S\n",
       "4  562.22547      S"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientBoostFold2 = sklearn.ensemble.AdaBoostClassifier(estimator = tree.DecisionTreeClassifier(max_depth=1), n_estimators = 36, learning_rate = 19.5, algorithm=\"SAMME\")\n",
    "\n",
    "gradientBoostFold2.fit(X_train_kmers, y_train)\n",
    "\n",
    "test_preds = gradientBoostFold2.predict(X_test_kmers)\n",
    "\n",
    "test_preds_df = pd.DataFrame(data={\"genome_id\":y_test_ids, \"y_pred\":test_preds})\n",
    "test_preds_df.to_csv(\"gradientBoostFold2.csv\", index=False) # IMPORTANT: Do not save the index\n",
    "test_preds_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Gradient Boost Model\n",
    "Based on the results of the three optimized models, the best model would be the one trained on fold 1 (Forest with a size of 25, a tree depth of 23, and a learning rate of 4.019), with a resulting accuracy of 0.8523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Perhaps simple is better in this case, as the random forest yielded better accuracies compared to the gradient boost across the board. The best model that I came up with was the random forest model trained on the middle fold of data.\n",
    "\n",
    "This is, of course, only the best model in the narrow scope of the data used and the default sklearn packages.\n",
    "\n",
    "I also did not have the chance to compare the models against each other, or to find the balanced accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etbg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
